{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b5caeb6-9130-41aa-89df-34f6a1588a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 93174\n",
      "Test rows: 39933\n",
      "Test rows (should be 39933): 39933\n",
      "Train columns: ['ID', 'loan_amnt', 'loan_term', 'interest_rate', 'loan_grade', 'loan_subgrade', 'job_experience', 'home_ownership', 'annual_income', 'income_verification_status', 'loan_purpose', 'state_code', 'debt_to_income', 'delinq_2yrs', 'public_records', 'revolving_balance', 'total_acc', 'interest_receive', 'application_type', 'last_week_pay', 'total_current_balance', 'total_revolving_limit', 'default']\n",
      "default\n",
      "0    71045\n",
      "1    22129\n",
      "Name: count, dtype: int64\n",
      "Categorical cols: ['loan_term', 'loan_grade', 'loan_subgrade', 'job_experience', 'home_ownership', 'income_verification_status', 'loan_purpose', 'state_code', 'application_type']\n",
      "Numeric cols: ['loan_amnt', 'interest_rate', 'annual_income', 'debt_to_income', 'delinq_2yrs', 'public_records', 'revolving_balance', 'total_acc', 'interest_receive', 'last_week_pay', 'total_current_balance', 'total_revolving_limit']\n",
      "X shape: (93174, 21) X_test shape: (39933, 21)\n"
     ]
    }
   ],
   "source": [
    "# baseline_submission.py\n",
    "# Requirements:\n",
    "# pip install pandas numpy scikit-learn lightgbm category_encoders\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "# -------------------------\n",
    "# Config\n",
    "# -------------------------\n",
    "TRAIN_PATH = \"Train_set.csv\"\n",
    "TEST_PATH = \"Test_set.csv\"\n",
    "TARGET = \"default\"\n",
    "ID_COL = \"ID\"            # adjust if your id column name differs\n",
    "N_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "SUBMISSION_FILE = \"submission.csv\"\n",
    "\n",
    "# -------------------------\n",
    "# Load data\n",
    "# -------------------------\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "\n",
    "print(\"Train rows:\", len(train))\n",
    "print(\"Test rows:\", len(test))\n",
    "\n",
    "# Quick check: user expects 39933 entries in submission\n",
    "# If test has different shape you may need to confirm with organisers.\n",
    "print(\"Test rows (should be 39933):\", len(test))\n",
    "\n",
    "# -------------------------\n",
    "# Basic EDA (quick)\n",
    "# -------------------------\n",
    "print(\"Train columns:\", train.columns.tolist())\n",
    "print(train[TARGET].value_counts(dropna=False))\n",
    "\n",
    "# -------------------------\n",
    "# Preprocessing helpers\n",
    "# -------------------------\n",
    "def reduce_mem(df):\n",
    "    # very simple memory reducer (optional)\n",
    "    for col in df.select_dtypes(include=[\"int64\"]).columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"integer\")\n",
    "    for col in df.select_dtypes(include=[\"float64\"]).columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"float\")\n",
    "    return df\n",
    "\n",
    "train = reduce_mem(train)\n",
    "test = reduce_mem(test)\n",
    "\n",
    "# -------------------------\n",
    "# Feature selection / engineering\n",
    "# -------------------------\n",
    "# Heuristic: treat object columns as categorical. Numeric columns keep as-is.\n",
    "# Drop any columns you know are leakage or not available at inference.\n",
    "\n",
    "all_data = pd.concat([train.drop(columns=[TARGET]), test], axis=0, sort=False)\n",
    "cat_cols = all_data.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = [c for c in all_data.columns if c not in cat_cols and c != ID_COL]\n",
    "\n",
    "print(\"Categorical cols:\", cat_cols)\n",
    "print(\"Numeric cols:\", num_cols)\n",
    "\n",
    "# Basic imputation:\n",
    "# - Numeric -> median\n",
    "# - Categorical -> fill \"MISSING\" then label-encode\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"__MISSING__\")\n",
    "\n",
    "# Fit imputers on combined data (to avoid unseen category at test)\n",
    "all_num = all_data[num_cols]\n",
    "all_cat = all_data[cat_cols].astype(str) if len(cat_cols) else pd.DataFrame(index=all_data.index)\n",
    "\n",
    "all_num_imputed = pd.DataFrame(num_imputer.fit_transform(all_num), columns=num_cols, index=all_num.index)\n",
    "all_cat_imputed = pd.DataFrame(cat_imputer.fit_transform(all_cat), columns=cat_cols, index=all_cat.index)\n",
    "\n",
    "# Label encode categoricals\n",
    "label_encoders = {}\n",
    "for c in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    all_cat_imputed[c] = le.fit_transform(all_cat_imputed[c].astype(str))\n",
    "    label_encoders[c] = le\n",
    "\n",
    "# Reassemble processed data\n",
    "processed = pd.concat([all_num_imputed, all_cat_imputed], axis=1)\n",
    "processed[ID_COL] = all_data[ID_COL].values\n",
    "# Split back to train/test\n",
    "proc_train = processed.iloc[:len(train)].reset_index(drop=True)\n",
    "proc_test = processed.iloc[len(train):].reset_index(drop=True)\n",
    "\n",
    "X = proc_train.drop(columns=[ID_COL])\n",
    "y = train[TARGET].values\n",
    "X_test = proc_test.drop(columns=[ID_COL])\n",
    "\n",
    "print(\"X shape:\", X.shape, \"X_test shape:\", X_test.shape)\n",
    "# -------------------------\n",
    "# LightGBM training with StratifiedKFold\n",
    "# -------------------------\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_error\",   # binary_error gives 0/1 error; we'll compute accuracy later\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 64,\n",
    "    \"max_depth\": -1,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"seed\": RANDOM_STATE,\n",
    "    \"verbosity\": -1\n",
    "}\n",
    "\n",
    "oof_preds = np.zeros(len(X))\n",
    "test_preds = np.zeros(len(X_test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c23427fc-5b43-40ba-9d31-5381c6e96c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_error: 0.131837\tvalid_1's binary_error: 0.137913\n",
      "[200]\ttraining's binary_error: 0.114061\tvalid_1's binary_error: 0.125731\n",
      "[300]\ttraining's binary_error: 0.102725\tvalid_1's binary_error: 0.121277\n",
      "[400]\ttraining's binary_error: 0.0934947\tvalid_1's binary_error: 0.118809\n",
      "[500]\ttraining's binary_error: 0.0849757\tvalid_1's binary_error: 0.118218\n",
      "[600]\ttraining's binary_error: 0.076631\tvalid_1's binary_error: 0.11795\n",
      "Early stopping, best iteration is:\n",
      "[513]\ttraining's binary_error: 0.0834194\tvalid_1's binary_error: 0.117789\n",
      "Fold 1 accuracy: 0.88221\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_error: 0.130361\tvalid_1's binary_error: 0.13861\n",
      "[200]\ttraining's binary_error: 0.111901\tvalid_1's binary_error: 0.127663\n",
      "[300]\ttraining's binary_error: 0.100994\tvalid_1's binary_error: 0.123477\n",
      "[400]\ttraining's binary_error: 0.0924617\tvalid_1's binary_error: 0.123424\n",
      "Early stopping, best iteration is:\n",
      "[308]\ttraining's binary_error: 0.100216\tvalid_1's binary_error: 0.123155\n",
      "Fold 2 accuracy: 0.87684\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_error: 0.128818\tvalid_1's binary_error: 0.134854\n",
      "[200]\ttraining's binary_error: 0.111834\tvalid_1's binary_error: 0.126643\n",
      "[300]\ttraining's binary_error: 0.101061\tvalid_1's binary_error: 0.123746\n",
      "[400]\ttraining's binary_error: 0.0918848\tvalid_1's binary_error: 0.122565\n",
      "[500]\ttraining's binary_error: 0.0842109\tvalid_1's binary_error: 0.121921\n",
      "[600]\ttraining's binary_error: 0.0763225\tvalid_1's binary_error: 0.12176\n",
      "[700]\ttraining's binary_error: 0.0680986\tvalid_1's binary_error: 0.120955\n",
      "[800]\ttraining's binary_error: 0.060787\tvalid_1's binary_error: 0.120794\n",
      "Early stopping, best iteration is:\n",
      "[727]\ttraining's binary_error: 0.0660191\tvalid_1's binary_error: 0.120097\n",
      "Fold 3 accuracy: 0.87990\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_error: 0.128537\tvalid_1's binary_error: 0.138235\n",
      "[200]\ttraining's binary_error: 0.111338\tvalid_1's binary_error: 0.1282\n",
      "[300]\ttraining's binary_error: 0.101853\tvalid_1's binary_error: 0.125731\n",
      "[400]\ttraining's binary_error: 0.0927971\tvalid_1's binary_error: 0.12337\n",
      "[500]\ttraining's binary_error: 0.0844524\tvalid_1's binary_error: 0.123477\n",
      "Early stopping, best iteration is:\n",
      "[443]\ttraining's binary_error: 0.0893626\tvalid_1's binary_error: 0.12278\n",
      "Fold 4 accuracy: 0.87722\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_error: 0.129139\tvalid_1's binary_error: 0.138779\n",
      "[200]\ttraining's binary_error: 0.111605\tvalid_1's binary_error: 0.12767\n",
      "[300]\ttraining's binary_error: 0.101288\tvalid_1's binary_error: 0.12504\n",
      "[400]\ttraining's binary_error: 0.0923531\tvalid_1's binary_error: 0.124343\n",
      "Early stopping, best iteration is:\n",
      "[338]\ttraining's binary_error: 0.0976523\tvalid_1's binary_error: 0.123269\n",
      "Fold 5 accuracy: 0.87673\n",
      "OOF accuracy: 0.8785820078562689\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"Fold {fold}\")\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "    lgb_val = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    # Optionally set scale_pos_weight for imbalanced classes:\n",
    "    # pos = sum(y_train==1); neg = sum(y_train==0)\n",
    "    # params['scale_pos_weight'] = neg / (pos+1e-9)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        num_boost_round=5000,\n",
    "        valid_sets=[lgb_train, lgb_val],\n",
    "        callbacks=[lgb.early_stopping(100),lgb.log_evaluation(100)]\n",
    "    )\n",
    "    \n",
    "    # Predict\n",
    "    val_pred_prob = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    val_pred = (val_pred_prob >= 0.5).astype(int)\n",
    "    oof_preds[val_idx] = val_pred\n",
    "    \n",
    "    test_pred_prob = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    test_preds += test_pred_prob / N_FOLDS\n",
    "    \n",
    "    # feature importance\n",
    "    fold_imp = pd.DataFrame({\n",
    "        \"feature\": X.columns,\n",
    "        \"importance\": model.feature_importance(importance_type=\"gain\"),\n",
    "        \"fold\": fold\n",
    "    })\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_imp], axis=0)\n",
    "    \n",
    "    acc = accuracy_score(y_val, val_pred)\n",
    "    print(f\"Fold {fold} accuracy: {acc:.5f}\")\n",
    "    gc.collect()\n",
    "    \n",
    "# OOF accuracy\n",
    "oof_pred_labels = (oof_preds >= 0.5).astype(int)\n",
    "oof_acc = accuracy_score(y, oof_pred_labels)\n",
    "print(\"OOF accuracy:\", oof_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1e899c8-7aca-4d77-8900-2631d6f1e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final test predictions (thresholded)\n",
    "final_test_labels = (test_preds >= 0.5).astype(int)\n",
    "\n",
    "# -------------------------\n",
    "# Submission\n",
    "# -------------------------\n",
    "submission = pd.DataFrame({\n",
    "    ID_COL: proc_test[ID_COL].values,\n",
    "    TARGET: final_test_labels\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e406b9f8-a7c7-4248-bdda-0201a2a34a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission rows: 39933\n",
      "Wrote submission.csv\n",
      "Top features:\n",
      " feature\n",
      "last_week_pay                 113263.194933\n",
      "interest_rate                  86248.466365\n",
      "loan_subgrade                  42218.741955\n",
      "total_current_balance          37168.161636\n",
      "interest_receive               22001.352601\n",
      "total_revolving_limit          19074.209397\n",
      "debt_to_income                 16939.106927\n",
      "loan_term                      14793.241593\n",
      "loan_amnt                      11918.528693\n",
      "revolving_balance              11692.348105\n",
      "annual_income                  10612.132073\n",
      "loan_grade                     10056.002086\n",
      "total_acc                       9783.303072\n",
      "state_code                      6806.067883\n",
      "income_verification_status      4568.518214\n",
      "job_experience                  2375.447043\n",
      "loan_purpose                    2111.137820\n",
      "delinq_2yrs                     1598.723091\n",
      "public_records                  1238.601614\n",
      "home_ownership                  1219.048389\n",
      "Name: importance, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: ensure correct number of rows (problem expects 39933)\n",
    "print(\"Submission rows:\", len(submission))\n",
    "submission.to_csv(SUBMISSION_FILE, index=False)\n",
    "print(f\"Wrote {SUBMISSION_FILE}\")\n",
    "\n",
    "# -------------------------\n",
    "# Helpful extras (feature importance)\n",
    "# -------------------------\n",
    "imp_mean = feature_importance_df.groupby(\"feature\")[\"importance\"].mean().sort_values(ascending=False)\n",
    "print(\"Top features:\\n\", imp_mean.head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
